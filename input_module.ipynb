{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle as cPickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'cifar100_data'\n",
    "full_data_dir = 'cifar100_data/cifar-100-python/train'\n",
    "vali_dir = 'cifar100_data/cifar-100-python/test'\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 32\n",
    "IMG_HEIGHT = 32\n",
    "IMG_DEPTH = 3\n",
    "NUM_CLASS = 100\n",
    "\n",
    "TRAIN_RANDOM_LABEL = False  # Want to use random label for train data?\n",
    "VALI_RANDOM_LABEL = False  # Want to use random label for validation?\n",
    "\n",
    "NUM_TRAIN_BATCH = 1  # How many batches of files you want to read in, from 0 to 5)\n",
    "EPOCH_SIZE = 50000 * NUM_TRAIN_BATCH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  read_all_data(path, is_random_label):\n",
    "    '''\n",
    "    The training data contains five data batches in total. The validation data has only one\n",
    "    batch. This function takes the directory of one batch of data and returns the images and\n",
    "    corresponding labels as numpy arrays\n",
    "\n",
    "    :param path: the directory of one batch of data\n",
    "    :param is_random_label: do you want to use random labels?\n",
    "    :return: image numpy arrays and label numpy arrays\n",
    "    '''\n",
    "    fo = open(path, 'rb')\n",
    "    dicts = cPickle.load(fo)\n",
    "    fo.close()\n",
    "\n",
    "    data = dicts['data']\n",
    "    if is_random_label is False:\n",
    "        label = np.array(dicts['fine_labels'])\n",
    "    else:\n",
    "        labels = np.random.randint(low=0, high=100, size=10000)\n",
    "        label = np.array(labels)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_with_transform(address_list, shuffle=True, is_random_label=False):\n",
    "    \"\"\"\n",
    "    This function reads all training or validation data, shuffles them if needed, and returns the\n",
    "    images and the corresponding labels as numpy arrays\n",
    "\n",
    "    :param address_list: a list of paths of cPickle files\n",
    "    :return: concatenated numpy array of data and labels. Data are in 4D arrays: [num_images,\n",
    "    image_height, image_width, image_depth] and labels are in 1D arrays: [num_images]\n",
    "    \"\"\"\n",
    "    data = np.array([]).reshape([0, IMG_WIDTH * IMG_HEIGHT * IMG_DEPTH])\n",
    "    label = np.array([])\n",
    "\n",
    "    for address in address_list:\n",
    "        print ('Reading images from ' + address)\n",
    "        batch_data, batch_label = read_all_data(address, is_random_label)\n",
    "        # Concatenate along axis 0 by default\n",
    "        data = np.concatenate((data, batch_data))\n",
    "        label = np.concatenate((label, batch_label))\n",
    "\n",
    "    num_data = len(label)\n",
    "\n",
    "    # This reshape order is really important. Don't change\n",
    "    # Reshape is correct. Double checked\n",
    "    data = data.reshape((num_data, IMG_HEIGHT * IMG_WIDTH, IMG_DEPTH), order='F')\n",
    "    data = data.reshape((num_data, IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH))\n",
    "\n",
    "    if shuffle is True:\n",
    "        print ('Shuffling')\n",
    "        order = np.random.permutation(num_data)\n",
    "        data = data[order, ...]\n",
    "        label = label[order]\n",
    "\n",
    "    data = data.astype(np.float32)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_flip(image, axis):\n",
    "    '''\n",
    "    Flip an image at 50% possibility\n",
    "    :param image: a 3 dimensional numpy array representing an image\n",
    "    :param axis: 0 for vertical flip and 1 for horizontal flip\n",
    "    :return: 3D image after flip\n",
    "    '''\n",
    "    flip_prop = np.random.randint(low=0, high=2)\n",
    "    if flip_prop == 0:\n",
    "        image = np.flip(image, axis)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitening_image(image_np):\n",
    "    '''\n",
    "    Performs per_image_whitening\n",
    "    :param image_np: a 4D numpy array representing a batch of images\n",
    "    :return: the image numpy array after whitened\n",
    "    '''\n",
    "    for i in range(len(image_np)):\n",
    "        mean = np.mean(image_np[i, ...])\n",
    "        # Use adjusted standard deviation here, in case the std == 0.\n",
    "        std = np.max([np.std(image_np[i, ...]), 1.0 / np.sqrt(IMG_HEIGHT * IMG_WIDTH * IMG_DEPTH)])\n",
    "        image_np[i, ...] = (image_np[i, ...] - mean) / std\n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop_and_flip(batch_data, padding_size):\n",
    "    '''\n",
    "    Helper to random crop and random flip a batch of images\n",
    "    :param padding_size: int. how many layers of 0 padding was added to each side\n",
    "    :param batch_data: a 4D batch array\n",
    "    :return: randomly cropped and flipped image\n",
    "    '''\n",
    "    cropped_batch = np.zeros(len(batch_data) * IMG_HEIGHT * IMG_WIDTH * IMG_DEPTH).reshape(\n",
    "        len(batch_data), IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH)\n",
    "\n",
    "    for i in range(len(batch_data)):\n",
    "        x_offset = np.random.randint(low=0, high=2 * padding_size, size=1)[0]\n",
    "        y_offset = np.random.randint(low=0, high=2 * padding_size, size=1)[0]\n",
    "        cropped_batch[i, ...] = batch_data[i, ...][x_offset:x_offset + IMG_HEIGHT,\n",
    "                                y_offset:y_offset + IMG_WIDTH, :]\n",
    "\n",
    "        cropped_batch[i, ...] = horizontal_flip(image=cropped_batch[i, ...], axis=1)\n",
    "\n",
    "    return cropped_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(batch_data, padding_size):\n",
    "    '''\n",
    "    Helper to random crop and random flip a batch of images\n",
    "    :param padding_size: int. how many layers of 0 padding was added to each side\n",
    "    :param batch_data: a 4D batch array\n",
    "    :return: randomly cropped and flipped image\n",
    "    '''\n",
    "    cropped_batch = np.zeros(len(batch_data) * IMG_HEIGHT * IMG_WIDTH * IMG_DEPTH).reshape(\n",
    "        len(batch_data), IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH)\n",
    "\n",
    "    for i in range(len(batch_data)):\n",
    "        x_offset = np.random.randint(low=0, high=2 * padding_size, size=1)[0]\n",
    "        y_offset = np.random.randint(low=0, high=2 * padding_size, size=1)[0]\n",
    "        cropped_batch[i, ...] = batch_data[i, ...][x_offset:x_offset + IMG_HEIGHT,\n",
    "                                y_offset:y_offset + IMG_WIDTH, :]\n",
    "\n",
    "\n",
    "    return cropped_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(padding_size):\n",
    "    '''\n",
    "    Read all the train data into numpy array and add padding_size of 0 paddings on each side of the\n",
    "    image\n",
    "    :param padding_size: int. how many layers of zero pads to add on each side?\n",
    "    :return: all the train data and corresponding labels\n",
    "    '''\n",
    "    path_list = []\n",
    "    # for i in range(1, NUM_TRAIN_BATCH + 1):\n",
    "    #     path_list.append(full_data_dir + str(i))\n",
    "    path_list.append(full_data_dir)\n",
    "    data, label = load_data_with_transform(path_list, is_random_label=TRAIN_RANDOM_LABEL)\n",
    "\n",
    "    pad_width = ((0, 0), (padding_size, padding_size), (padding_size, padding_size), (0, 0))\n",
    "    data = np.pad(data, pad_width=pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_validation_data():\n",
    "    '''\n",
    "    Read in validation data. Whitening at the same time\n",
    "    :return: Validation image data as 4D numpy array. Validation labels as 1D numpy array\n",
    "    '''\n",
    "    validation_array, validation_labels = read_all_data([vali_dir],\n",
    "                                                             is_random_label=VALI_RANDOM_LABEL)\n",
    "    validation_array = whitening_image(validation_array)\n",
    "\n",
    "    return validation_array, validation_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
